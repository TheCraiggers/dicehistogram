<h2>How Fair Is My D20?</h2>

<p>An automatic system for rolling a polyhedral die and taking photos of the rolls; extracting the image of just the die from those images; clustering the images of the die by which face is shown; and analyzing the results.<p>

<p>I was inspired in part by the <a href="http://www.awesomedice.com/blog/353/d20-dice-randomness-test-chessex-vs-gamescience/">Awesome Dice Blog's 2012 post</a> comparing d20 fairness between two manufacturers. (<a href="http://blog.codeoptimism.com/most-d20-dice-are-notably-imbalanced/">Christopher Galpin in 2014</a> links to a number of other interesting analyses.) They rolled and tallied by hand.</p>

<h2>Results</h2>

TODO

<h2>Hardware Setup (Die Roller and Camera)</h2>

<iframe width="640" height="360" src="https://www.youtube.com/embed/UdA5ydENTHY?rel=0" frameborder="0" allowfullscreen></iframe>

<p>A microcontroller runs a servo motor to shake a small tub, and triggers a camera to take pictures. More details: <a href="TODO">Arduino sketch and hardware parts list</a>.

<h3>Construction</h3>

<p>The main container is an empty (and well washed) ice cream carton, chosen for its flat bottom and sloping sides. The servo motor's arm is taped to the side, and a paperclip makes the pivot on the opposite side. A simple U of cardboard forms the stand (with weights on it to keep it still). The servo motor is mounted in a snugly fitting hole cut in the cardboard.</p>

<p>The LEDs are placed through slots in the carton, facing downward. This keeps them from shining back up at the camera. One power supply wire is inside the carton, and one outside (soldered in place). A small piece of translucent plastic (from a nametag holder) makes a ramp so the die can roll over the LEDs/wire.</p>

<p>Plastic wrap with a rubber-band provides a cover. This prevents the die from rolling out when the carton tips down for each roll. With the LEDs on and the room lights off, there is negligable glare.</p>

<p>The camera is a Nikon D90, using a long (55-200mm) lens for low perspective distortion across the visual field. It is triggered via wired remote (though the GPS/remote port was defective and <a href="TODO">required repair</a>); and powered via its AC adapter port (using <a href="http://www.thingiverse.com/thing:1107374">a 3D-printed plug</a>).</p>

</h3>Performance</h3>

<ul>
<li>Timing: In several thousand rolls, only a few do not fully settle before the photograph is taken. With this timing, it captures about 790 rolls per hour (or one every 4&frac12; seconds).</li>
<li>Repeatability: Despite quick construction, the servo and its taped attachment reliably returns the tub to the same position, closely enough for analysis.</li>
</ul>

<h3>Improvements</h3>

<ul>
<li>Noise. The servo motor's whine carries, as does the sound of the die hitting the inside of the paper tub. Heavier or less resonant materials might help, as could lining the container with something like felt.</li>
<li>Turbulence. The smaller dice (d4 and d6) slide down the tub's side when it tilts down, rather than rolling; this can lead to repeatedly rolling the same number. Bumpy sides on the container, or tilting further down, might help.</li>
</ul>

<h2>Software Explanation</h2>

There are two computer-vision tasks in this process: finding the die within the larger photo of the die-rolling area; and figuring out which picture is of which face of the die.

<h3>Cropping</h3>

<p>A photo of the rolled die is diffed against a reference image.</p>

<img src="arduino/151102dicehistogramreference.jpg" />
<img src="arduino/151102dicehistogramdie.jpg" />

<p>The result is scanned for areas of high difference to find the die. The die is flood-filled to find its area; the then image of the die is cropped out and saved.</p>

<img src="arduino/151102dicehistogramdiffwithscan.jpg" />

<p>The above image was obtained from running `crop.py` with `--debug`. The base (mostly black) image is the diff of the image with the die and the reference image. The blue lines are where the image was scanned, the red highlighted line segments are where a large difference was detected. The green dotted box was the detected bounds of the die.</p>

<p>Scanning is done on a scaled down version of the images, but the cropped image of the die is saved at full resolution for better feature detection.</p>

<img src="arduino/151102dicehistogramcrop.jpg" />

<h3>Clustering</h3>

<p>Images of the die are compared using features, detected and matched using OpenCV.</p>

<img src="arduino/151102dicehistogramfeaturematchgood.jpg" />

<p>These screenshots from the <code>find_obj.py</code> OpenCV demo show good (above) and bad (below) matches. The white rectangles on the right side are the homography: the area of the right image that matches up with the left image. Good matches not only have a high number of matching points, but a simple (translation and rotation only) homography with low distortion.</p>

<img src="arduino/151102dicehistogramfeaturematchbad.jpg" />
<img src="arduino/151102dicehistogramfeaturematchskew.jpg" />

<p>The first step builds a list of dissimilar representative images, against which all other images get compared. Each representative gets a list of matching members (the images showing the same face of the die).</p>

<p>This tends to result in big groups for each of the sides of the die, and a bunch of small groups (1-10 each) of images that didn't match any of the representatives well. So a second step takes the small groups and compares them to members of the larger groups (not just their representative images) to find a match.</p>

<a href="arduino/151102dicehistograminprogress.jpg"><img src="arduino/151102dicehistograminprogress20p.jpg" /></a>

<p>From a partial run on a d8, the work-in-progress with a number of small disconnected groups (above), and the consolidated groups (below).

<a href="arduino/151102dicehistogramreparented.jpg"><img src="arduino/151102dicehistogramreparented20p.jpg" /></a>
